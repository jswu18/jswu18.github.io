

<!doctype html>
<html lang="en" class="no-js">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>Generalised Variational Inference - James Wu</title>







<meta property="og:locale" content="en-US">
<meta property="og:site_name" content="James Wu">
<meta property="og:title" content="Generalised Variational Inference">


  <link rel="canonical" href="https://jswu18.github.io/posts/2023/07/generalised-variational-inference/">
  <meta property="og:url" content="https://jswu18.github.io/posts/2023/07/generalised-variational-inference/">



  <meta property="og:description" content="The Bayesian PosteriorStatistical modelling is traditionally focused on characterising an underlying data generation process. In a Bayesian context, this involves updating the beliefs on a model’s parameterisation. Given a model parameterised by $\theta$, Bayesian inference can be viewed as an update rule on $\pi(\theta)$, the prior belief of $\theta$. For new observations $x_{1:N}$ and a likelihood function $p(x_{1:N}|\theta)$, the belief for $\theta$ is updated as:\begin{align}q_B^(\theta) = \frac{p(x_{1:N}|\theta) \pi(\theta)}{\int_{\Theta} p(x_{1:N}|\theta) d \pi(\theta)}\label{bayesian-posterior}\end{align}where $q_B^(\theta)$ is known as the \textit{Bayesian posterior}. The validity of the Bayesian Posterior relies on three assumptions concerning the prior, the likelihood, and the normaliser.">





  

  





  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2023-07-09T00:00:00-07:00">








  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "James Wu",
      "url" : "https://jswu18.github.io",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->


<link href="https://jswu18.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="James Wu Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="https://jswu18.github.io/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    

<!-- start custom head snippets -->

<link rel="apple-touch-icon" sizes="57x57" href="https://jswu18.github.io/images/apple-touch-icon-57x57.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="60x60" href="https://jswu18.github.io/images/apple-touch-icon-60x60.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="72x72" href="https://jswu18.github.io/images/apple-touch-icon-72x72.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="76x76" href="https://jswu18.github.io/images/apple-touch-icon-76x76.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="114x114" href="https://jswu18.github.io/images/apple-touch-icon-114x114.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="120x120" href="https://jswu18.github.io/images/apple-touch-icon-120x120.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="144x144" href="https://jswu18.github.io/images/apple-touch-icon-144x144.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="152x152" href="https://jswu18.github.io/images/apple-touch-icon-152x152.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="180x180" href="https://jswu18.github.io/images/apple-touch-icon-180x180.png?v=M44lzPylqQ">
<link rel="icon" type="image/png" href="https://jswu18.github.io/images/favicon-32x32.png?v=M44lzPylqQ" sizes="32x32">
<link rel="icon" type="image/png" href="https://jswu18.github.io/images/android-chrome-192x192.png?v=M44lzPylqQ" sizes="192x192">
<link rel="icon" type="image/png" href="https://jswu18.github.io/images/favicon-96x96.png?v=M44lzPylqQ" sizes="96x96">
<link rel="icon" type="image/png" href="https://jswu18.github.io/images/favicon-16x16.png?v=M44lzPylqQ" sizes="16x16">
<link rel="manifest" href="https://jswu18.github.io/images/manifest.json?v=M44lzPylqQ">
<link rel="mask-icon" href="https://jswu18.github.io/images/safari-pinned-tab.svg?v=M44lzPylqQ" color="#000000">
<link rel="shortcut icon" href="/images/favicon.ico?v=M44lzPylqQ">
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="https://jswu18.github.io/images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="https://jswu18.github.io/images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="https://jswu18.github.io/assets/css/academicons.css"/>

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg"><a href="https://jswu18.github.io/">James Wu</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://jswu18.github.io/publications/">Publications</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://jswu18.github.io/year-archive/">Blog Posts</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://jswu18.github.io/files/james-wu-resume.pdf">CV</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    





<div id="main" role="main">
  


  <div class="sidebar sticky">
  



<div itemscope itemtype="http://schema.org/Person">

  <div class="author__avatar">
    
    	<img src="https://jswu18.github.io/images/profile.png" class="author__avatar" alt="James Wu">
    
  </div>

  <div class="author__content">
    <h3 class="author__name">James Wu</h3>
    <p class="author__bio">Computational Statistics & Machine Learning @ UCL</p>
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> London, UK</li>
      
      
      
      
        <li><a href="mailto:jswu18@gmail.com"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i> Email</a></li>
      
      
       
      
      
      
      
        <li><a href="https://www.linkedin.com/in/jswu18"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
      
      
      
      
      
      
        <li><a href="https://github.com/jswu18"><i class="fab fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Generalised Variational Inference">
    <meta itemprop="description" content="The Bayesian PosteriorStatistical modelling is traditionally focused on characterising an underlying data generation process. In a Bayesian context, this involves updating the beliefs on a model’s parameterisation. Given a model parameterised by $\theta$, Bayesian inference can be viewed as an update rule on $\pi(\theta)$, the prior belief of $\theta$. For new observations $x_{1:N}$ and a likelihood function $p(x_{1:N}|\theta)$, the belief for $\theta$ is updated as:\begin{align}q_B^(\theta) = \frac{p(x_{1:N}|\theta) \pi(\theta)}{\int_{\Theta} p(x_{1:N}|\theta) d \pi(\theta)}\label{bayesian-posterior}\end{align}where $q_B^(\theta)$ is known as the \textit{Bayesian posterior}. The validity of the Bayesian Posterior relies on three assumptions concerning the prior, the likelihood, and the normaliser.">
    <meta itemprop="datePublished" content="July 09, 2023">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 class="page__title" itemprop="headline">Generalised Variational Inference
</h1>
          
            <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 


  
	  12 minute read
	
</p>
          
        
        
        
          <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2023-07-09T00:00:00-07:00">July 09, 2023</time></p>
        
        
             
<!--        -->
    
        </header>
      

      <section class="page__content" itemprop="text">
        <h2 id="the-bayesian-posterior">The Bayesian Posterior</h2>
<p>Statistical modelling is traditionally focused on characterising an underlying data generation process. In a Bayesian context, this involves updating the beliefs on a model’s parameterisation. Given a model parameterised by $\theta$, Bayesian inference can be viewed as an update rule on $\pi(\theta)$, the prior belief of $\theta$. For new observations $x_{1:N}$ and a likelihood function $p(x_{1:N}|\theta)$, the belief for $\theta$ is updated as:
\begin{align}
q_B^<em>(\theta) = \frac{p(x_{1:N}|\theta) \pi(\theta)}{\int_{\Theta} p(x_{1:N}|\theta) d \pi(\theta)}
\label{bayesian-posterior}
\end{align}
where $q_B^</em>(\theta)$ is known as the \textit{Bayesian posterior}. The validity of the Bayesian Posterior relies on three assumptions concerning the prior, the likelihood, and the normaliser.</p>

<h3 id="the-prior-assumption">The Prior Assumption</h3>
<p>Bayesian inference assumes a prior $\pi(\theta)$ that is well-specified and informative of $\theta^*$, the `true’ model parameters. The prior is interpreted as embodying \textit{all} previous knowledge about the data generating process such as previously observed data. Alternatively, the prior can also be interpreted as representing \textit{pseudo} observations about how we believe the data behaves.</p>

<h3 id="the-likelihood-assumption">The Likelihood Assumption</h3>

<table>
  <tbody>
    <tr>
      <td>Bayesian inference assumes that there exists $\theta^* \in \Theta$, such that $x_i \sim p(x_n</td>
      <td>\theta^<em>)$ for some unknown but fixed $\theta^</em>$. In other words $p(x_n</td>
      <td>\theta^<em>)$, the likelihood function that is chosen is \textit{exactly} the true data generating process and is parameterised by $\theta$. In this case, the problem is simply a matter of finding $\theta^</em>$.</td>
    </tr>
  </tbody>
</table>

<h3 id="the-normaliser-assumption">The Normaliser Assumption</h3>

<table>
  <tbody>
    <tr>
      <td>Bayesian inference assumes that the normaliser $\int_{\Theta} p(x_{1:N}</td>
      <td>\theta) d \pi(\theta)$ is a tractable integral or is computationally tractable. Computational tractability assumes access to  adequate computational resources and time to reasonably approximate the integral. This means that in traditional Bayesian inference, the computational complexities of evaluating $q_B^*(\theta)$ can be ignored.</td>
    </tr>
  </tbody>
</table>

<h2 id="the-bayesian-posterior-breaks-down">The Bayesian Posterior Breaks Down</h2>
<p>In contrast to traditional statistical modelling, larger-scaled models like Bayesian Neural Networks are typically focused on \textit{predictive performance} rather than \textit{model specification}. In these settings, the three  assumptions for the Bayesian posterior quickly breakdown, making it no longer reasonable to view $q_B^*(\theta)$ as a Bayesian belief update.</p>

<h3 id="the-prior-is-mis-specified">The Prior is Mis-specified</h3>
<p>Larger-scaled models are often over-parameterised black box models, such as the weights of a Bayesian neural network. These parameters are essentially uninterpretable and priors are chosen out of convenience (i.e. Gaussians) with little thought given to their true parameterisation. In these settings, it is no longer practical to view $\pi(\theta)$ as a prior belief in the parameters of the data generating model as it is most definitely mis-specified.</p>

<h3 id="the-likelihood-model-is-mis-specified">The Likelihood Model is Mis-specified</h3>
<p>Although model mis-specification occurs in traditional Bayesian inference, techniques such as hypothesis testing, residual analysis, and domain expertise can help guide the construction of a reasonably well-specified setting. However, the intentions behind using larger-scaled models is completely different. It is not to \textit{understand} the data generating process, but rather to have superior \textit{predictive performance}. With over-parameterisation, these black box models are most definitely mis-specified but often provide high prediction accuracy. As such, model parameters are typically chosen through an optimisation process (i.e. gradient descent), no longer adhering to the spirit of traditional Bayesian inference. For larger-scaled models, it is almost never fair to assume that $x_n \sim p(x|\theta)$ for \textit{any} $\theta \in \Theta$.</p>

<h3 id="the-normaliser-is-intractability">The Normaliser is Intractability</h3>
<p>The use of conjugate priors is the only case when there exists closed form expressions for $\int_{\Theta} p(x_{1:N}|\theta) d \pi(\theta)$ to ensure tractable evaluation of $q_B^<em>(\theta)$. For over-parameterised black-box models, $q_B^</em>(\theta)$ will need to be approximated either through sampling approximations of the normaliser or variational approximations of $q_B^<em>(\theta)$.
\newline
\Samplers such as Metropolis Hastings or Markov Chain Monte Carlo only have convergence guarantees in the infinite limit. Acheiving this limit would require access to infinite computational resources and time, clearly impractical. 
\newline
\Approximating $q_B^</em>(\theta)$ involves solving for $q_A^<em>(\theta) \in \mathcal{Q}_{A}$, where $\mathcal{Q}_{A}$ is often viewed as distributions of a simpler form. For example mean field approximations define a family of distributions $\mathcal{Q}_{MF} = \left{\prod_i q_i(\theta_i)\right}$, a product of independent distributions. Variational inference is motivated to finding a $q_A^</em>(\theta) \in \mathcal{Q}<em>{A}$ that \textit{approximates} $q_B^*(\theta)$, through the minimisation of some divergence between the two, $D(q_A^*(\theta)| q_B^*(\theta))$. However the space of distributions $\mathcal{Q}</em>{A}$ is usually severely restrictive in its expressiveness and $q_A^<em>(\theta)$ is almost never a fair depiction of the structure of $q_B^</em>(\theta)$. Realistically, $\mathcal{Q}_{A}$ is chosen purely for computational convenience. With larger-scaled models, it is often no longer reasonable to assume that the normaliser of the Bayesian posterior will be tractable or that $q_B^*(\theta)$ can be reasonably approximated in a tractable manner.</p>

<h2 id="the-generalised-posterior">The Generalised Posterior</h2>
<p>Interpreting the mechanism behind calculating the Bayesian posterior in the context of optimisation can provide a more reasonable depiction of $q_B^<em>(\theta)$ for larger-scaled models. It can be shown that $q_B^</em>(\theta)$ solves a special case of a general variational inference (GVI) problem:
\begin{align}
q^<em>(\theta) = \argmin_{q \in \Pi} \left{ \mathbb{E}_{q(\theta)}\left[\sum_{n=1}^N \ell(\theta, x_n)\right] + D(q|\pi)\right}
\label{general-posterior}
\end{align}
where $q_B^</em>(\theta)$ is recovered by choosing the negative log-likelihood loss $\ell(\theta, \cdot) = -\log p(\cdot | \theta)$, the Kullback-Leibler divergence $D(\cdot | \pi) = \KLD(\cdot | \pi)$, and the feasible set $\Pi = \mathcal{P}(\Theta)$. No longer deriving $q_B^<em>(\theta)$ from a belief update, we are no longer burdened to fulfill the assumptions required for the Bayesian inference interpretation of $q_B^</em>(\theta)$. We can re-interpret the role of the prior, likelihood, and choosing tractable normaliser approximations, in the context of an optimisation problem.</p>

<h3 id="the-prior-is-a-regulariser">The Prior is a Regulariser</h3>
<p>In the optimisation context of (\ref{general-posterior}), we can see that the prior $\pi$ only exists in the divergence term. As such, $\pi$ defines the regulariser of an empirical risk minimisation optimisation problem which is solved by the Bayesian posterior $q_B^*(\theta)$. The choice of prior controls model complexity and prevents overfitting to the empirical risk. Unlike in the Bayesian interpretation, in this optimisation setup $\pi$ is no longer required to be a well-specified prior. Thus in larger-scaled models where prior mis-specification is almost guaranteed, it is more appropriate to view the prior as a regulariser on model complexity rather than a prior belief in the model parameters.</p>

<h3 id="the-likelihood-is-a-loss">The Likelihood is a Loss</h3>
<p>From (\ref{general-posterior}), the likelihood term exists only in the expectation. Note that the empirical risk is defined as:
\begin{align}
\mathcal{E}(\theta) = \mathbb{E}<em>{q(\theta)}\left[\sum</em>{n=1}^N \ell\left(x_n, \theta\right)\right]
\label{empirical-risk}
\end{align}
where $\ell$ is some loss function. We can see that defining $\ell$ as the negative log-likelihood, we recover an empirical risk of the model over empirical data that is equivalent to the expectation term of (\ref{general-posterior}). This interprets the likelihood function as a special loss definition for an optimisation problem. In other words, $q_B^<em>(\theta)$ is the minimiser of a regularised empirical risk with a log-likelihood loss, defined with respect to its predictive performance rather than its belief updates on model parameters. By pivoting from the Bayesian interpretation of $q_B^</em>(\theta)$, we no longer need to have a well-specified likelihood function because we can view the posterior as empirical risk minimisation for a special loss definition.</p>

<h3 id="model-approximations-as-optimisation-constraints">Model Approximations as Optimisation Constraints</h3>
<p>Rather than viewing $q_A^<em>(\theta)$ as an approximation of $q_B^</em>(\theta)$, it is more practical to view $q_A^<em>(\theta)$ as the solution to an optimisation problem, where we are \textit{constrained} to $\mathcal{Q}_{A}$. In other words, we are not attempting to \textit{approximate} $q_B^</em>(\theta)$ but rather we are finding the \textit{optimal} solution $q_A^<em>(\theta)$ in the space $\mathcal{Q}_{A}$. With mis-specified priors and likelihood functions, $q_B^</em>(\theta)$  is no longer a true Bayesian posterior anyways, and so there’s little meaning behind these approximations. Especially with the reframing in optimisation, we are more concerned with finding the model in our feasible set $\mathcal{Q}<em>{A}$ with the best predictive performance rather than the model that most accurately depicts the data generation process.
\subsection{The Bayesian Posterior in a Wider Context}
By $\textit{generalising}$ the Bayesian posterior update mechanism to an optimisation problem, we can understand more general posteriors of the form $q^*(\theta)$. Although it is defined as a solution to an optimisation problem, $q^*(\theta)$ can still be viewed as a form of posterior. The optimisation in ($\ref{general-posterior}$) still provides a mechanism to generate an updated belief of $\theta$ given new data $x</em>{1:N}$. Generalised Variational Inference provides a flexible framework for constructing these \textit{pseudo}-posteriors where the \textit{Bayesian} posterior $q_B^*(\theta)$ can be recovered as a special case in a wider context.</p>

<h2 id="theoretical-guarantees-from-gvi">Theoretical Guarantees from GVI</h2>
<p>Loss minimisation of larger-scaled machine learning models is typically over a highly non-convex optimisation problem. The parameters of these models $f_{\theta}$ are typically trained through the minimisation:
\begin{align}
\min_{\theta \in \Theta} \sum_{n=1}^N\ell_n(x_n, \theta)
\label{loss-minimisation}
\end{align}
where $\ell_n(x_n, \theta)$ quantifies the predictive performance of a model’s parameterisation $\theta$ for training observation $(x_n, y_n)$, such as the squared loss $\ell_{sq}(\theta) = \sum_{n=1}^N \left(y_n - f_{\theta}(x_n)\right)^2$. Typically $\theta^*$, the minimiser of (\ref{loss-minimisation}), is in $ \mathbb{R}^J$ a finite dimensional space where $J$ is the number of parameters in $f_{\theta}$.<br />
\newline
In practice a reasonable local minima can achieve high predictive performance, and so the non-convex nature of the parameter space is often ignored. However without the guaranteed existence of a unique minimiser, learning theory is unable to make theoretical claims about these larger-scaled models. By convexifying (\ref{loss-minimisation}), we recover the minimisation problem of the form ($\ref{general-posterior}$). Thus the GVI posterior is also a reframing of modern machine learning models sp that we can understand them in the context of learning theory.</p>
<h3 id="probabilistic-lifting">Probabilistic Lifting</h3>
<p>To convexify ($\ref{loss-minimisation}$), we begin by lifting the problem from a finite-dimensional parameter space $\mathbb{R}^J$ to an infinite-dimensional probability space $\mathcal{P}(\mathbb{R}^J)$, the space of measures on $\mathbb{R}^J$:
\begin{align}
    \min_{Q \in \mathcal{P}(\mathbb{R}^J)} \int \left( \sum_{n=1}^N\ell_n(x_n, \theta)\right) dq(\theta)
\label{risk-minimisation}
\end{align}
where $\hat{q}$, minimisers of (\ref{risk-minimisation}), can correspond to  $\hat{\theta}$, minimisers of (\ref{loss-minimisation}), through the Dirac measure $\hat{q}(\theta) = \delta_{\hat{\theta}} (\theta)$. This first reformulation changes a non-convex problem with respect to $\theta$ to a linear problem with respect to $q$. 
\To show this, consider two minimisers $\theta_A$ and $\theta_B$ such that:
\begin{align}
    \sum_{n=1}^N\ell_n(x_n, \theta_A) = \sum_{n=1}^N\ell_n(x_n, \theta_B) = \min_{\theta \in \Theta} \sum_{n=1}^N\ell_n(x_n, \theta), \text{ where } \theta_A \neq \theta_B
\end{align}
with corresponding measures $\delta_{\theta_A}, \delta_{\theta_B} \in \mathcal{P}(\mathbb{R}^J)$ such that:
\begin{align}
    \int \left( \sum_{n=1}^N\ell_n(x_n, \theta)\right) d\delta_{\theta_A} = \int \left( \sum_{n=1}^N\ell_n(x_n, \theta)\right) d\delta_{\theta_B} = \min_{q \in \mathcal{P}(\mathbb{R}^J)} \int \left( \sum_{n=1}^N\ell_n(x_n, \theta)\right) dq(\theta)
    \label{ex-risk-minimisers}
\end{align}
By defining $q_t = (1-t)\delta_{\theta_A} + t\delta_{\theta_B}$ for $t \in [0, 1]$:
\begin{align}
    \label{show-linear-defn}
    \int \left( \sum_{n=1}^N\ell_n(x_n, \theta)\right) dq_t(\theta) &amp;= \int \left( \sum_{n=1}^N\ell_n(x_n, \theta)\right) d\left\big((1-t)\delta_{\theta_A} + t\delta_{\theta_B}\right\big)<br />
    \label{show-linear-linear-operator}
    &amp;= (1-t)\int \left( \sum_{n=1}^N\ell_n(x_n, \theta)\right) d\delta_{\theta_A} + t \int \left( \sum_{n=1}^N\ell_n(x_n, \theta)\right) d\delta_{\theta_B}<br />
    \label{show-linear-minimisers}
    &amp;= \min_{Q \in \mathcal{P}(\mathbb{R}^J)} \int \left( \sum_{n=1}^N\ell_n(x_n, \theta)\right) dq(\theta)
\end{align}
where ($\ref{show-linear-linear-operator}$) follows by linearity and ($\ref{show-linear-minimisers}$) follows from ($\ref{ex-risk-minimisers}$). Thus ($\ref{risk-minimisation}$) is a linear problem in $q$.</p>
<h3 id="convexification-through-regularisation">Convexification through Regularisation</h3>
<p>By adding a strictly convex and positive regulariser $D_r(q| \pi)$ to our linear objective ($\ref{risk-minimisation}$), we ensure a strictly convex objective, guaranteeing the existence of a $\textit{unique}$ minimiser:
\begin{align}
    q^* = \argmin_{q \in \mathcal{P}(\mathbb{R}^J)} \left{\int \left( \sum_{n=1}^N\ell_n(x_n, \theta)\right) dq(\theta) + \lambda D_r(q | \pi)\right}
\label{regularised-risk-minimisation}
\end{align}
where $\lambda &gt; 0$. The solution of ($\ref{regularised-risk-minimisation}$) is no longer a minimiser of ($\ref{risk-minimisation}$). But rather, $\lambda$ balances the tradeoff between the empirical risk minimisation of ($\ref{risk-minimisation}$) and deviance from a prior measure $\pi$, which in this context we can view as a reference measure.<br />
\newline 
Choosing $\Pi =\mathcal{P}(\mathbb{R}^J)$, $\ell(\theta) = \sum_{n=1}^N\ell_n(x_n, \theta)$, and $D(q| \pi) = \lambda D_r(q| \pi)$, we see that ($\ref{regularised-risk-minimisation}$) fits into the general form of ($\ref{general-posterior}$), recovering the GVI posterior.</p>
<h3 id="uniqueness-of-the-gvi-posterior">Uniqueness of the GVI posterior</h3>
<p>Through probabilistic lifting and convexification, we can formulate a GVI posterior that guarantees a unique minimiser for the non-convex problem in (\ref{loss-minimisation}). This posterior is a unique weighted averaging of the local and global minima of (\ref{loss-minimisation}), and equivalently (\ref{risk-minimisation}) where each minima is weighted by the discrepancy from the prior reference measure $\lambda D_r(q | \pi)$. By guaranteeing a unique minimiser, the GVI framework can provide theoretical guarantees for learning larger-scaled machine learning models.</p>

<h2 id="references">References</h2>
<p><a id="1">[1]</a>
Anastasiou, A., Barp, A., Briol, F. X., Ebner, B., Gaunt, R. E., Ghaderinezhad, F., … &amp; Swan, Y. (2021). Stein’s Method Meets Statistics: A Review of Some Recent Developments. arXiv preprint arXiv:2105.03481.</p>

<p><a id="2">[2]</a>
Barp, A., Briol, F. X., Duncan, A., Girolami, M., &amp; Mackey, L. (2019). Minimum stein discrepancy estimators. Advances in Neural Information Processing Systems, 32.</p>

        
      </section>

      <footer class="page__meta">
        
        


  




  
  
  

  <p class="page__taxonomy">
    <strong><i class="fa fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="https://jswu18.github.io/tags/#bayesian-inference" class="page__taxonomy-item" rel="tag">Bayesian Inference</a><span class="sep">, </span>
    
      
      
      <a href="https://jswu18.github.io/tags/#generalised-variational-inference" class="page__taxonomy-item" rel="tag">Generalised Variational Inference</a>
    
    </span>
  </p>




      </footer>

      

<section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=https://jswu18.github.io/posts/2023/07/generalised-variational-inference/" class="btn btn--twitter" title="Share on Twitter"><i class="fab fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https://jswu18.github.io/posts/2023/07/generalised-variational-inference/" class="btn btn--facebook" title="Share on Facebook"><i class="fab fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://jswu18.github.io/posts/2023/07/generalised-variational-inference/" class="btn btn--linkedin" title="Share on LinkedIn"><i class="fab fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>

      


  <nav class="pagination">
    
      <a href="https://jswu18.github.io/posts/2023/05/expectation-maximisation/" class="pagination--pager" title="Expectation Maximisation
">Previous</a>
    
    
      <a href="#" class="pagination--pager disabled">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      
        <h4 class="page__related-title">You May Also Enjoy</h4>
      
      <div class="grid__wrapper">
        
          





<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="https://jswu18.github.io/posts/2023/05/expectation-maximisation/" rel="permalink">Expectation Maximisation
</a>
      
    </h2>
    
    
      <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 


  
	  5 minute read
	
</p>
    

        
         <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2023-05-21T00:00:00-07:00">May 21, 2023</time></p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>Expectation maximisation is a powerful algorithm that can be applied to a wide variety of problems, including clustering, mixture models, and hidden Markov models. In this post, I will present the general formulation of the algorithm and apply it to the k-means clustering problem as an example.</p>

</p>
    

<!--    -->

  </article>
</div>

        
          





<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="https://jswu18.github.io/posts/2022/10/kernel-stein-discrepancy/" rel="permalink">The Kernel Stein Discrepancy
</a>
      
    </h2>
    
    
      <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 


  
	  11 minute read
	
</p>
    

        
         <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2022-10-12T00:00:00-07:00">October 12, 2022</time></p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>Stein discrepancies (SDs) calculate a statistical divergence between a known density \(\mathbb{P}\) and samples from an unknown distribution \(\mathbb{Q}\). In this post, we will introduce the Stein discrepancy, in particular the Langevin Kernel Stein Discrepancy (KSD), a common form of Stein discrepancy.</p>

</p>
    

<!--    -->

  </article>
</div>

        
          





<div class="grid__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="https://jswu18.github.io/posts/2021/06/images/gaussian-processes/" rel="permalink">Gaussian Processes: A Hands On Introduction
</a>
      
    </h2>
    
    
      <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 


  
	  6 minute read
	
</p>
    

        
         <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2021-06-18T00:00:00-07:00">June 18, 2021</time></p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>There are many online resources for understanding Gaussian Processes. In this post, I present a more hands on way of introducing the topic that I found quite helpful and intuitive for myself.</p>

</p>
    

<!--    -->

  </article>
</div>

        
      </div>
    </div>
  
</div>


    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->
<a href="/sitemap/">Sitemap</a>
<!-- end custom footer snippets -->

        

<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
<!--    -->
<!--    -->
    
      <li><a href="http://github.com/jswu18"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a></li>
    
<!--    -->
    <li><a href="https://jswu18.github.io/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2023 James Wu. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    <script src="https://jswu18.github.io/assets/js/main.min.js"></script>




  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>






  </body>
</html>

